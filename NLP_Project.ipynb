{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning For NLP : Prediction of Sex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table des matières"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports et Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from preprocessing import preprocess_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"transcriptions_with_sex.csv\")\n",
    "name_data = pd.read_csv(\"firstname_with_sex.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_line</th>\n",
       "      <th>groundtruth</th>\n",
       "      <th>prediction</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ebb26ada-044c-4c62-9dbc-a9c8d505d31c</td>\n",
       "      <td>surname: Chardon firstname: Marie occupation: ...</td>\n",
       "      <td>nom: Chardon prénom: Marie date_naissance: 30 ...</td>\n",
       "      <td>femme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>338496f5-e4ca-43ac-aa5c-429cb3f6ac00</td>\n",
       "      <td>surname: Lhopital firstname: Louis-Jean occupa...</td>\n",
       "      <td>nom: Lhopital prénom: Louis Jean date_naissanc...</td>\n",
       "      <td>homme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e6a279da-9b6f-4f49-b498-64857bc50d1e</td>\n",
       "      <td>surname: Papin firstname: Marie occupation: id...</td>\n",
       "      <td>nom: Pyrin prénom: Marie date_naissance: 55 re...</td>\n",
       "      <td>femme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7534deca-39e8-4f00-be17-c12460015de1</td>\n",
       "      <td>surname: Lavocat firstname: Marie link: femme ...</td>\n",
       "      <td>nom: Lavocat prénom: Marie date_naissance: 187...</td>\n",
       "      <td>femme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ef334a66-a504-418a-9872-e7c9db923488</td>\n",
       "      <td>surname: Benne firstname: Marguerite age: 78</td>\n",
       "      <td>nom: Benne prénom: Marguerite date_naissance: ...</td>\n",
       "      <td>femme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>1d92738a-cffe-4aee-ab10-db04c37f7405</td>\n",
       "      <td>surname: Burlurut firstname: Pétronille occupa...</td>\n",
       "      <td>nom: Burlurut prénom: Gihromille date_naissanc...</td>\n",
       "      <td>femme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>09440055-7972-4135-a537-e6c5a1f2aeb2</td>\n",
       "      <td>surname: Combey firstname: Alexandre occupatio...</td>\n",
       "      <td>nom: Comberf prénom: Alexandre date_naissance:...</td>\n",
       "      <td>homme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>4d387278-12c3-410c-bdf0-c5c603479764</td>\n",
       "      <td>surname: Collin firstname: Marguerite occupati...</td>\n",
       "      <td>nom: Collin prénom: Marguerite date_naissance:...</td>\n",
       "      <td>femme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>623b95de-f87c-4844-a7f7-361088eed83a</td>\n",
       "      <td>surname: Dumont firstname: Etienne link: fils ...</td>\n",
       "      <td>nom: Dumont prénom: Etienne date_naissance: 19...</td>\n",
       "      <td>homme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>26d7839c-16a1-486e-9736-83e500fb72e5</td>\n",
       "      <td>surname: Renaut firstname: Antoinette link: be...</td>\n",
       "      <td>nom: Renaut prénom: Antoinette date_naissance:...</td>\n",
       "      <td>femme</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>241 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             subject_line  \\\n",
       "0    ebb26ada-044c-4c62-9dbc-a9c8d505d31c   \n",
       "1    338496f5-e4ca-43ac-aa5c-429cb3f6ac00   \n",
       "2    e6a279da-9b6f-4f49-b498-64857bc50d1e   \n",
       "3    7534deca-39e8-4f00-be17-c12460015de1   \n",
       "4    ef334a66-a504-418a-9872-e7c9db923488   \n",
       "..                                    ...   \n",
       "236  1d92738a-cffe-4aee-ab10-db04c37f7405   \n",
       "237  09440055-7972-4135-a537-e6c5a1f2aeb2   \n",
       "238  4d387278-12c3-410c-bdf0-c5c603479764   \n",
       "239  623b95de-f87c-4844-a7f7-361088eed83a   \n",
       "240  26d7839c-16a1-486e-9736-83e500fb72e5   \n",
       "\n",
       "                                           groundtruth  \\\n",
       "0    surname: Chardon firstname: Marie occupation: ...   \n",
       "1    surname: Lhopital firstname: Louis-Jean occupa...   \n",
       "2    surname: Papin firstname: Marie occupation: id...   \n",
       "3    surname: Lavocat firstname: Marie link: femme ...   \n",
       "4        surname: Benne firstname: Marguerite age: 78    \n",
       "..                                                 ...   \n",
       "236  surname: Burlurut firstname: Pétronille occupa...   \n",
       "237  surname: Combey firstname: Alexandre occupatio...   \n",
       "238  surname: Collin firstname: Marguerite occupati...   \n",
       "239  surname: Dumont firstname: Etienne link: fils ...   \n",
       "240  surname: Renaut firstname: Antoinette link: be...   \n",
       "\n",
       "                                            prediction    sex  \n",
       "0    nom: Chardon prénom: Marie date_naissance: 30 ...  femme  \n",
       "1    nom: Lhopital prénom: Louis Jean date_naissanc...  homme  \n",
       "2    nom: Pyrin prénom: Marie date_naissance: 55 re...  femme  \n",
       "3    nom: Lavocat prénom: Marie date_naissance: 187...  femme  \n",
       "4    nom: Benne prénom: Marguerite date_naissance: ...  femme  \n",
       "..                                                 ...    ...  \n",
       "236  nom: Burlurut prénom: Gihromille date_naissanc...  femme  \n",
       "237  nom: Comberf prénom: Alexandre date_naissance:...  homme  \n",
       "238  nom: Collin prénom: Marguerite date_naissance:...  femme  \n",
       "239  nom: Dumont prénom: Etienne date_naissance: 19...  homme  \n",
       "240  nom: Renaut prénom: Antoinette date_naissance:...  femme  \n",
       "\n",
       "[241 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanieluu/Documents/ENSAE/3A/S2/NLP/nlp_project/preprocessing.py:36: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for col_name, value in row.iteritems():\n"
     ]
    }
   ],
   "source": [
    "column_to_extract = \"groundtruth\"\n",
    "columns_to_drop = [\"subject_line\", \"prediction\"]\n",
    "preprocessed_df = preprocess_pipeline(df, name_data, column_to_extract, columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>employer</th>\n",
       "      <th>link</th>\n",
       "      <th>firstname</th>\n",
       "      <th>observation</th>\n",
       "      <th>occupation</th>\n",
       "      <th>lob</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>surname</th>\n",
       "      <th>civil_status</th>\n",
       "      <th>age</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>texte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nom: Chardon prénom: Marie date_naissance: 30 ...</td>\n",
       "      <td>None</td>\n",
       "      <td>fille</td>\n",
       "      <td>marie</td>\n",
       "      <td>None</td>\n",
       "      <td>idem</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Chardon</td>\n",
       "      <td>None</td>\n",
       "      <td>30</td>\n",
       "      <td>10145.0</td>\n",
       "      <td>2390322.0</td>\n",
       "      <td>subject_line_ebb26ada-044c-4c62-9dbc-a9c8d505d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nom: Lhopital prénom: Louis Jean date_naissanc...</td>\n",
       "      <td>None</td>\n",
       "      <td>chef</td>\n",
       "      <td>louis</td>\n",
       "      <td>None</td>\n",
       "      <td>sp</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Lhopital</td>\n",
       "      <td>None</td>\n",
       "      <td>67</td>\n",
       "      <td>750498.0</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>subject_line_338496f5-e4ca-43ac-aa5c-429cb3f6a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nom: Pyrin prénom: Marie date_naissance: 55 re...</td>\n",
       "      <td>idem</td>\n",
       "      <td>idem</td>\n",
       "      <td>marie</td>\n",
       "      <td>None</td>\n",
       "      <td>idem</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Papin</td>\n",
       "      <td>None</td>\n",
       "      <td>15</td>\n",
       "      <td>10145.0</td>\n",
       "      <td>2390322.0</td>\n",
       "      <td>subject_line_e6a279da-9b6f-4f49-b498-64857bc50...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nom: Lavocat prénom: Marie date_naissance: 187...</td>\n",
       "      <td>None</td>\n",
       "      <td>femme</td>\n",
       "      <td>marie</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Rigny</td>\n",
       "      <td>1875</td>\n",
       "      <td>Lavocat</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10145.0</td>\n",
       "      <td>2390322.0</td>\n",
       "      <td>subject_line_7534deca-39e8-4f00-be17-c12460015...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nom: Benne prénom: Marguerite date_naissance: ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>marguerite</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Benne</td>\n",
       "      <td>None</td>\n",
       "      <td>78</td>\n",
       "      <td>1441.0</td>\n",
       "      <td>813859.0</td>\n",
       "      <td>subject_line_ef334a66-a504-418a-9872-e7c9db923...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>nom: Burlurut prénom: Gihromille date_naissanc...</td>\n",
       "      <td>None</td>\n",
       "      <td>épouse</td>\n",
       "      <td>pétronille</td>\n",
       "      <td>None</td>\n",
       "      <td>sans</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Burlurut</td>\n",
       "      <td>None</td>\n",
       "      <td>61</td>\n",
       "      <td>30.0</td>\n",
       "      <td>13067.0</td>\n",
       "      <td>subject_line_1d92738a-cffe-4aee-ab10-db04c37f7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>nom: Comberf prénom: Alexandre date_naissance:...</td>\n",
       "      <td>None</td>\n",
       "      <td>son</td>\n",
       "      <td>alexandre</td>\n",
       "      <td>None</td>\n",
       "      <td>idem</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Combey</td>\n",
       "      <td>None</td>\n",
       "      <td>39</td>\n",
       "      <td>90238.0</td>\n",
       "      <td>413.0</td>\n",
       "      <td>subject_line_09440055-7972-4135-a537-e6c5a1f2a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>nom: Collin prénom: Marguerite date_naissance:...</td>\n",
       "      <td>idem</td>\n",
       "      <td>épouse</td>\n",
       "      <td>marguerite</td>\n",
       "      <td>None</td>\n",
       "      <td>idem</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Collin</td>\n",
       "      <td>None</td>\n",
       "      <td>38</td>\n",
       "      <td>1441.0</td>\n",
       "      <td>813859.0</td>\n",
       "      <td>subject_line_4d387278-12c3-410c-bdf0-c5c603479...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>nom: Dumont prénom: Etienne date_naissance: 19...</td>\n",
       "      <td>None</td>\n",
       "      <td>fils</td>\n",
       "      <td>etienne</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>idem</td>\n",
       "      <td>1900</td>\n",
       "      <td>Dumont</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>211297.0</td>\n",
       "      <td>898.0</td>\n",
       "      <td>subject_line_623b95de-f87c-4844-a7f7-361088eed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>nom: Renaut prénom: Antoinette date_naissance:...</td>\n",
       "      <td>None</td>\n",
       "      <td>belle</td>\n",
       "      <td>antoinette</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Rigny</td>\n",
       "      <td>1849</td>\n",
       "      <td>Renaut</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>326.0</td>\n",
       "      <td>150155.0</td>\n",
       "      <td>subject_line_26d7839c-16a1-486e-9736-83e500fb7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>241 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            prediction employer    link  \\\n",
       "0    nom: Chardon prénom: Marie date_naissance: 30 ...     None   fille   \n",
       "1    nom: Lhopital prénom: Louis Jean date_naissanc...     None    chef   \n",
       "2    nom: Pyrin prénom: Marie date_naissance: 55 re...     idem    idem   \n",
       "3    nom: Lavocat prénom: Marie date_naissance: 187...     None   femme   \n",
       "4    nom: Benne prénom: Marguerite date_naissance: ...     None    None   \n",
       "..                                                 ...      ...     ...   \n",
       "236  nom: Burlurut prénom: Gihromille date_naissanc...     None  épouse   \n",
       "237  nom: Comberf prénom: Alexandre date_naissance:...     None     son   \n",
       "238  nom: Collin prénom: Marguerite date_naissance:...     idem  épouse   \n",
       "239  nom: Dumont prénom: Etienne date_naissance: 19...     None    fils   \n",
       "240  nom: Renaut prénom: Antoinette date_naissance:...     None   belle   \n",
       "\n",
       "      firstname observation occupation    lob birth_date   surname  \\\n",
       "0         marie        None       idem   None       None   Chardon   \n",
       "1         louis        None         sp   None       None  Lhopital   \n",
       "2         marie        None       idem   None       None     Papin   \n",
       "3         marie        None       None  Rigny       1875   Lavocat   \n",
       "4    marguerite        None       None   None       None     Benne   \n",
       "..          ...         ...        ...    ...        ...       ...   \n",
       "236  pétronille        None       sans   None       None  Burlurut   \n",
       "237   alexandre        None       idem   None       None    Combey   \n",
       "238  marguerite        None       idem   None       None    Collin   \n",
       "239     etienne        None       None   idem       1900    Dumont   \n",
       "240  antoinette        None       None  Rigny       1849    Renaut   \n",
       "\n",
       "    civil_status   age      male     female  \\\n",
       "0           None    30   10145.0  2390322.0   \n",
       "1           None    67  750498.0     2720.0   \n",
       "2           None    15   10145.0  2390322.0   \n",
       "3           None  None   10145.0  2390322.0   \n",
       "4           None    78    1441.0   813859.0   \n",
       "..           ...   ...       ...        ...   \n",
       "236         None    61      30.0    13067.0   \n",
       "237         None    39   90238.0      413.0   \n",
       "238         None    38    1441.0   813859.0   \n",
       "239         None  None  211297.0      898.0   \n",
       "240         None  None     326.0   150155.0   \n",
       "\n",
       "                                                 texte  \n",
       "0    subject_line_ebb26ada-044c-4c62-9dbc-a9c8d505d...  \n",
       "1    subject_line_338496f5-e4ca-43ac-aa5c-429cb3f6a...  \n",
       "2    subject_line_e6a279da-9b6f-4f49-b498-64857bc50...  \n",
       "3    subject_line_7534deca-39e8-4f00-be17-c12460015...  \n",
       "4    subject_line_ef334a66-a504-418a-9872-e7c9db923...  \n",
       "..                                                 ...  \n",
       "236  subject_line_1d92738a-cffe-4aee-ab10-db04c37f7...  \n",
       "237  subject_line_09440055-7972-4135-a537-e6c5a1f2a...  \n",
       "238  subject_line_4d387278-12c3-410c-bdf0-c5c603479...  \n",
       "239  subject_line_623b95de-f87c-4844-a7f7-361088eed...  \n",
       "240  subject_line_26d7839c-16a1-486e-9736-83e500fb7...  \n",
       "\n",
       "[241 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataframe = extract_groundtruth(df[[\"groundtruth\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.drop(\"prediction\", axis=1)\n",
    "for column in new_dataframe.columns:\n",
    "    data[column] = new_dataframe[column]\n",
    "preprocessed_data = data.drop([\"groundtruth\", \"subject_line\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>firstname</th>\n",
       "      <th>age</th>\n",
       "      <th>surname</th>\n",
       "      <th>link</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>lob</th>\n",
       "      <th>observation</th>\n",
       "      <th>civil_status</th>\n",
       "      <th>employer</th>\n",
       "      <th>occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>femme</td>\n",
       "      <td>Marie</td>\n",
       "      <td>30</td>\n",
       "      <td>Chardon</td>\n",
       "      <td>fille</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>idem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>homme</td>\n",
       "      <td>Louis</td>\n",
       "      <td>67</td>\n",
       "      <td>Lhopital</td>\n",
       "      <td>chef</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>sp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>femme</td>\n",
       "      <td>Marie</td>\n",
       "      <td>15</td>\n",
       "      <td>Papin</td>\n",
       "      <td>idem</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>idem</td>\n",
       "      <td>idem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>femme</td>\n",
       "      <td>Marie</td>\n",
       "      <td>None</td>\n",
       "      <td>Lavocat</td>\n",
       "      <td>femme</td>\n",
       "      <td>1875</td>\n",
       "      <td>Rigny</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>femme</td>\n",
       "      <td>Marguerite</td>\n",
       "      <td>78</td>\n",
       "      <td>Benne</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>femme</td>\n",
       "      <td>Pétronille</td>\n",
       "      <td>61</td>\n",
       "      <td>Burlurut</td>\n",
       "      <td>épouse</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>sans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>homme</td>\n",
       "      <td>Alexandre</td>\n",
       "      <td>39</td>\n",
       "      <td>Combey</td>\n",
       "      <td>son</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>idem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>femme</td>\n",
       "      <td>Marguerite</td>\n",
       "      <td>38</td>\n",
       "      <td>Collin</td>\n",
       "      <td>épouse</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>idem</td>\n",
       "      <td>idem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>homme</td>\n",
       "      <td>Etienne</td>\n",
       "      <td>None</td>\n",
       "      <td>Dumont</td>\n",
       "      <td>fils</td>\n",
       "      <td>1900</td>\n",
       "      <td>idem</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>femme</td>\n",
       "      <td>Antoinette</td>\n",
       "      <td>None</td>\n",
       "      <td>Renaut</td>\n",
       "      <td>belle</td>\n",
       "      <td>1849</td>\n",
       "      <td>Rigny</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>241 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sex   firstname   age   surname    link birth_date    lob observation  \\\n",
       "0    femme       Marie    30   Chardon   fille       None   None        None   \n",
       "1    homme       Louis    67  Lhopital    chef       None   None        None   \n",
       "2    femme       Marie    15     Papin    idem       None   None        None   \n",
       "3    femme       Marie  None   Lavocat   femme       1875  Rigny        None   \n",
       "4    femme  Marguerite    78     Benne    None       None   None        None   \n",
       "..     ...         ...   ...       ...     ...        ...    ...         ...   \n",
       "236  femme  Pétronille    61  Burlurut  épouse       None   None        None   \n",
       "237  homme   Alexandre    39    Combey     son       None   None        None   \n",
       "238  femme  Marguerite    38    Collin  épouse       None   None        None   \n",
       "239  homme     Etienne  None    Dumont    fils       1900   idem        None   \n",
       "240  femme  Antoinette  None    Renaut   belle       1849  Rigny        None   \n",
       "\n",
       "    civil_status employer occupation  \n",
       "0           None     None       idem  \n",
       "1           None     None         sp  \n",
       "2           None     idem       idem  \n",
       "3           None     None       None  \n",
       "4           None     None       None  \n",
       "..           ...      ...        ...  \n",
       "236         None     None       sans  \n",
       "237         None     None       idem  \n",
       "238         None     idem       idem  \n",
       "239         None     None       None  \n",
       "240         None     None       None  \n",
       "\n",
       "[241 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessed_data.drop(\"sex\", axis=1)\n",
    "y = preprocessed_data[\"sex\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanieluu/Documents/ENSAE/3A/S2/NLP/nlp_project/preprocessing.py:37: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for col_name, value in row.iteritems():\n"
     ]
    }
   ],
   "source": [
    "X[\"texte\"] = X.apply(concatenate_column_names, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[['texte']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>firstname_Marie age_30 surname_Chardon link_fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>firstname_Louis age_67 surname_Lhopital link_c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>firstname_Marie age_15 surname_Papin link_idem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>firstname_Marie surname_Lavocat link_femme bir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>firstname_Marguerite age_78 surname_Benne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>firstname_Pétronille age_61 surname_Burlurut l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>firstname_Alexandre age_39 surname_Combey link...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>firstname_Marguerite age_38 surname_Collin lin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>firstname_Etienne surname_Dumont link_fils bir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>firstname_Antoinette surname_Renaut link_belle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>241 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 texte\n",
       "0    firstname_Marie age_30 surname_Chardon link_fi...\n",
       "1    firstname_Louis age_67 surname_Lhopital link_c...\n",
       "2    firstname_Marie age_15 surname_Papin link_idem...\n",
       "3    firstname_Marie surname_Lavocat link_femme bir...\n",
       "4            firstname_Marguerite age_78 surname_Benne\n",
       "..                                                 ...\n",
       "236  firstname_Pétronille age_61 surname_Burlurut l...\n",
       "237  firstname_Alexandre age_39 surname_Combey link...\n",
       "238  firstname_Marguerite age_38 surname_Collin lin...\n",
       "239  firstname_Etienne surname_Dumont link_fils bir...\n",
       "240  firstname_Antoinette surname_Renaut link_belle...\n",
       "\n",
       "[241 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      firstname_Marie age_30 surname_Chardon link_fi...\n",
       "1      firstname_Louis age_67 surname_Lhopital link_c...\n",
       "2      firstname_Marie age_15 surname_Papin link_idem...\n",
       "3      firstname_Marie surname_Lavocat link_femme bir...\n",
       "4              firstname_Marguerite age_78 surname_Benne\n",
       "                             ...                        \n",
       "236    firstname_Pétronille age_61 surname_Burlurut l...\n",
       "237    firstname_Alexandre age_39 surname_Combey link...\n",
       "238    firstname_Marguerite age_38 surname_Collin lin...\n",
       "239    firstname_Etienne surname_Dumont link_fils bir...\n",
       "240    firstname_Antoinette surname_Renaut link_belle...\n",
       "Name: texte, Length: 241, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Extract the \"texte\" column as input texts\n",
    "input_texts = X[\"texte\"].tolist()\n",
    "\n",
    "# Initialize the BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", num_labels=2\n",
    ")  # Assuming binary classification\n",
    "\n",
    "# Tokenize inputs\n",
    "# Note: tokenizer.batch_encode_plus expects a list of strings (texts)\n",
    "tokenized_inputs = tokenizer.batch_encode_plus(\n",
    "    input_texts, truncation=True, padding=True\n",
    ")\n",
    "\n",
    "# Assuming you're working with a downstream task, you can further process these tokenized inputs (e.g., convert to tensors, feed to the model for training)\n",
    "# Example:\n",
    "input_ids = tokenized_inputs[\"input_ids\"]\n",
    "attention_masks = tokenized_inputs[\"attention_mask\"]\n",
    "\n",
    "# Convert lists to tensors (assuming you're using PyTorch)\n",
    "input_ids = torch.tensor(input_ids)\n",
    "attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "# Example of feeding tokenized inputs to the model for training\n",
    "outputs = model(input_ids, attention_mask=attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-0.4182, -0.1032],\n",
       "        [-0.3789, -0.1344],\n",
       "        [-0.3669, -0.0426],\n",
       "        [-0.4228, -0.0794],\n",
       "        [-0.4484, -0.0880],\n",
       "        [-0.4450, -0.1157],\n",
       "        [-0.3779, -0.0637],\n",
       "        [-0.3967, -0.0848],\n",
       "        [-0.4219, -0.0552],\n",
       "        [-0.4053, -0.1350],\n",
       "        [-0.4329, -0.0738],\n",
       "        [-0.3956, -0.0635],\n",
       "        [-0.3529, -0.0570],\n",
       "        [-0.3810, -0.0646],\n",
       "        [-0.4245, -0.1295],\n",
       "        [-0.4250, -0.1226],\n",
       "        [-0.4042, -0.0984],\n",
       "        [-0.4304, -0.1112],\n",
       "        [-0.4161, -0.1095],\n",
       "        [-0.3665, -0.0704],\n",
       "        [-0.4077, -0.1069],\n",
       "        [-0.4262, -0.0704],\n",
       "        [-0.4430, -0.0371],\n",
       "        [-0.4478, -0.1403],\n",
       "        [-0.3877, -0.1216],\n",
       "        [-0.4122, -0.0839],\n",
       "        [-0.4148, -0.1259],\n",
       "        [-0.3927, -0.0864],\n",
       "        [-0.4262, -0.1210],\n",
       "        [-0.3854, -0.1160],\n",
       "        [-0.4317, -0.0724],\n",
       "        [-0.3270, -0.0632],\n",
       "        [-0.3977, -0.0871],\n",
       "        [-0.4578, -0.1065],\n",
       "        [-0.4118, -0.0697],\n",
       "        [-0.4239, -0.1029],\n",
       "        [-0.4442, -0.0994],\n",
       "        [-0.4237, -0.1267],\n",
       "        [-0.3938, -0.1004],\n",
       "        [-0.3279, -0.1116],\n",
       "        [-0.3940, -0.1009],\n",
       "        [-0.4155, -0.0613],\n",
       "        [-0.3674, -0.0801],\n",
       "        [-0.3955, -0.0669],\n",
       "        [-0.3817, -0.1343],\n",
       "        [-0.3947, -0.1144],\n",
       "        [-0.4145, -0.0477],\n",
       "        [-0.4137, -0.0925],\n",
       "        [-0.4722, -0.0992],\n",
       "        [-0.3464, -0.0388],\n",
       "        [-0.3728, -0.1472],\n",
       "        [-0.4355, -0.0993],\n",
       "        [-0.3315, -0.0781],\n",
       "        [-0.4244, -0.0864],\n",
       "        [-0.4262, -0.0784],\n",
       "        [-0.3988, -0.0913],\n",
       "        [-0.4161, -0.1149],\n",
       "        [-0.3291, -0.1006],\n",
       "        [-0.4645, -0.0815],\n",
       "        [-0.4184, -0.1309],\n",
       "        [-0.4385, -0.1301],\n",
       "        [-0.4043, -0.1028],\n",
       "        [-0.4317, -0.1036],\n",
       "        [-0.3911, -0.1226],\n",
       "        [-0.3519, -0.0827],\n",
       "        [-0.3959, -0.0769],\n",
       "        [-0.3928, -0.0805],\n",
       "        [-0.3862, -0.0865],\n",
       "        [-0.3841, -0.0839],\n",
       "        [-0.4402, -0.1014],\n",
       "        [-0.3825, -0.1259],\n",
       "        [-0.4044, -0.1095],\n",
       "        [-0.4318, -0.1243],\n",
       "        [-0.4547, -0.1112],\n",
       "        [-0.4138, -0.0916],\n",
       "        [-0.4076, -0.0624],\n",
       "        [-0.4318, -0.0661],\n",
       "        [-0.3928, -0.0406],\n",
       "        [-0.3907, -0.1035],\n",
       "        [-0.4081, -0.0834],\n",
       "        [-0.3893, -0.0654],\n",
       "        [-0.4154, -0.0812],\n",
       "        [-0.4239, -0.1171],\n",
       "        [-0.4305, -0.1004],\n",
       "        [-0.4510, -0.0840],\n",
       "        [-0.4235, -0.0838],\n",
       "        [-0.4607, -0.0955],\n",
       "        [-0.3826, -0.1019],\n",
       "        [-0.4110, -0.0608],\n",
       "        [-0.3871, -0.0748],\n",
       "        [-0.4076, -0.1008],\n",
       "        [-0.4021, -0.0635],\n",
       "        [-0.4163, -0.0863],\n",
       "        [-0.4100, -0.0384],\n",
       "        [-0.4191, -0.1385],\n",
       "        [-0.3963, -0.0846],\n",
       "        [-0.3970, -0.0717],\n",
       "        [-0.3519, -0.1073],\n",
       "        [-0.3519, -0.0701],\n",
       "        [-0.3886, -0.0337],\n",
       "        [-0.3415, -0.0066],\n",
       "        [-0.4548, -0.1078],\n",
       "        [-0.4506, -0.0762],\n",
       "        [-0.4255, -0.1082],\n",
       "        [-0.3774, -0.1506],\n",
       "        [-0.4528, -0.0838],\n",
       "        [-0.4255, -0.0551],\n",
       "        [-0.3902, -0.1661],\n",
       "        [-0.3739, -0.0877],\n",
       "        [-0.4258, -0.0871],\n",
       "        [-0.4143, -0.0490],\n",
       "        [-0.4421, -0.1156],\n",
       "        [-0.4084, -0.0157],\n",
       "        [-0.3957, -0.1064],\n",
       "        [-0.4044, -0.0901],\n",
       "        [-0.4169, -0.1029],\n",
       "        [-0.3930, -0.0654],\n",
       "        [-0.4166, -0.1209],\n",
       "        [-0.4420, -0.1160],\n",
       "        [-0.4395, -0.0657],\n",
       "        [-0.3953, -0.0873],\n",
       "        [-0.3994, -0.0538],\n",
       "        [-0.3920, -0.0909],\n",
       "        [-0.4146, -0.1195],\n",
       "        [-0.3467, -0.0381],\n",
       "        [-0.4210, -0.0818],\n",
       "        [-0.4205, -0.0138],\n",
       "        [-0.4002, -0.0859],\n",
       "        [-0.3935, -0.0758],\n",
       "        [-0.4259, -0.0793],\n",
       "        [-0.4230, -0.0586],\n",
       "        [-0.3875, -0.0355],\n",
       "        [-0.3504, -0.0581],\n",
       "        [-0.4369, -0.0533],\n",
       "        [-0.4140, -0.0986],\n",
       "        [-0.4278, -0.0439],\n",
       "        [-0.4151, -0.1260],\n",
       "        [-0.4359, -0.1208],\n",
       "        [-0.4369, -0.1088],\n",
       "        [-0.4023, -0.0621],\n",
       "        [-0.4180, -0.0603],\n",
       "        [-0.3969, -0.1136],\n",
       "        [-0.4159, -0.0576],\n",
       "        [-0.3880, -0.0858],\n",
       "        [-0.3295, -0.0491],\n",
       "        [-0.4283, -0.1081],\n",
       "        [-0.4234, -0.0959],\n",
       "        [-0.3942, -0.1030],\n",
       "        [-0.4481, -0.1065],\n",
       "        [-0.3741, -0.0968],\n",
       "        [-0.3906, -0.1000],\n",
       "        [-0.3991, -0.1247],\n",
       "        [-0.4240, -0.0920],\n",
       "        [-0.4596, -0.1168],\n",
       "        [-0.4092, -0.0918],\n",
       "        [-0.4165, -0.0880],\n",
       "        [-0.4362, -0.1527],\n",
       "        [-0.4199, -0.0470],\n",
       "        [-0.4277, -0.1206],\n",
       "        [-0.3711, -0.0299],\n",
       "        [-0.4006, -0.1057],\n",
       "        [-0.4102, -0.1535],\n",
       "        [-0.3865, -0.0858],\n",
       "        [-0.3989, -0.1266],\n",
       "        [-0.4284, -0.0848],\n",
       "        [-0.4005, -0.0853],\n",
       "        [-0.3890, -0.0298],\n",
       "        [-0.4414, -0.0776],\n",
       "        [-0.4177, -0.0888],\n",
       "        [-0.4126, -0.0915],\n",
       "        [-0.3828, -0.0793],\n",
       "        [-0.3788, -0.0837],\n",
       "        [-0.4192, -0.1122],\n",
       "        [-0.4024, -0.1053],\n",
       "        [-0.4244, -0.0557],\n",
       "        [-0.4113, -0.0862],\n",
       "        [-0.3766, -0.0845],\n",
       "        [-0.4033, -0.0971],\n",
       "        [-0.4328, -0.0980],\n",
       "        [-0.4385, -0.0657],\n",
       "        [-0.4436, -0.1234],\n",
       "        [-0.3903, -0.0925],\n",
       "        [-0.4405, -0.1067],\n",
       "        [-0.4065, -0.1164],\n",
       "        [-0.3869, -0.0841],\n",
       "        [-0.3601, -0.0299],\n",
       "        [-0.4278, -0.1144],\n",
       "        [-0.4264, -0.0886],\n",
       "        [-0.4193, -0.0865],\n",
       "        [-0.4182, -0.0493],\n",
       "        [-0.4342, -0.1304],\n",
       "        [-0.4094, -0.0964],\n",
       "        [-0.4460, -0.0819],\n",
       "        [-0.4051, -0.0818],\n",
       "        [-0.3932, -0.0660],\n",
       "        [-0.3749, -0.0739],\n",
       "        [-0.4389, -0.0897],\n",
       "        [-0.4387, -0.1211],\n",
       "        [-0.4158, -0.0777],\n",
       "        [-0.4309, -0.0942],\n",
       "        [-0.4475, -0.0534],\n",
       "        [-0.3358, -0.0742],\n",
       "        [-0.4220, -0.1348],\n",
       "        [-0.4426, -0.1131],\n",
       "        [-0.3504, -0.0258],\n",
       "        [-0.4166, -0.1400],\n",
       "        [-0.4164, -0.1143],\n",
       "        [-0.4307, -0.1046],\n",
       "        [-0.3973, -0.0738],\n",
       "        [-0.4123, -0.1153],\n",
       "        [-0.4153, -0.0674],\n",
       "        [-0.4049, -0.0453],\n",
       "        [-0.4266, -0.0995],\n",
       "        [-0.3659, -0.0973],\n",
       "        [-0.4058, -0.1381],\n",
       "        [-0.4309, -0.1096],\n",
       "        [-0.3936, -0.0417],\n",
       "        [-0.3437, -0.1154],\n",
       "        [-0.4295, -0.0925],\n",
       "        [-0.4289, -0.0586],\n",
       "        [-0.4846, -0.0915],\n",
       "        [-0.4258, -0.1082],\n",
       "        [-0.4047, -0.0640],\n",
       "        [-0.3830, -0.0716],\n",
       "        [-0.3920, -0.0822],\n",
       "        [-0.4151, -0.1389],\n",
       "        [-0.4201, -0.1152],\n",
       "        [-0.4289, -0.1258],\n",
       "        [-0.4295, -0.1074],\n",
       "        [-0.4207, -0.0981],\n",
       "        [-0.3893, -0.0572],\n",
       "        [-0.4024, -0.1159],\n",
       "        [-0.4234, -0.0873],\n",
       "        [-0.4012, -0.1201],\n",
       "        [-0.4290, -0.1051],\n",
       "        [-0.3953, -0.0885],\n",
       "        [-0.3475, -0.0956],\n",
       "        [-0.4226, -0.0783],\n",
       "        [-0.4141, -0.0831],\n",
       "        [-0.4309, -0.0917],\n",
       "        [-0.3952, -0.0434]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/emanieluu/Library/Python/3.9/lib/python/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Target 2 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m input_ids, attention_mask, labels \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     35\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 36\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[1;32m     38\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/models/bert/modeling_bert.py:1599\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mproblem_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle_label_classification\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1598\u001b[0m     loss_fct \u001b[38;5;241m=\u001b[39m CrossEntropyLoss()\n\u001b[0;32m-> 1599\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1600\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mproblem_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti_label_classification\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1601\u001b[0m     loss_fct \u001b[38;5;241m=\u001b[39m BCEWithLogitsLoss()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/functional.py:3029\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3028\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3029\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: Target 2 is out of bounds."
     ]
    }
   ],
   "source": [
    "texts = X['texte'].tolist()\n",
    "labels = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Split data into train, validation, test sets\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.1, random_state=42)\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(val_texts, val_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# Load pre-trained BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)  # 2 labels: male, female\n",
    "\n",
    "# Tokenize inputs\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True)\n",
    "\n",
    "# Create PyTorch datasets\n",
    "train_dataset = TensorDataset(torch.tensor(train_encodings['input_ids']), torch.tensor(train_encodings['attention_mask']), torch.tensor(train_labels))\n",
    "val_dataset = TensorDataset(torch.tensor(val_encodings['input_ids']), torch.tensor(val_encodings['attention_mask']), torch.tensor(val_labels))\n",
    "test_dataset = TensorDataset(torch.tensor(test_encodings['input_ids']), torch.tensor(test_encodings['attention_mask']), torch.tensor(test_labels))\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "\n",
    "# Training settings\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(3):\n",
    "    for batch in train_loader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch in test_loader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        _, predicted = torch.max(outputs.logits, dim=1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/emanieluu/Library/Python/3.9/lib/python/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Average training loss = 0.6654\n",
      "Epoch 2: Average training loss = 0.3803\n",
      "Epoch 3: Average training loss = 0.1728\n",
      "Validation accuracy: 0.9796\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Extract texte and target\n",
    "texts = X['texte'].tolist()\n",
    "targets = (\n",
    "    preprocessed_data[\"sex\"].apply(lambda x: 1 if x == \"homme\" else 0).tolist()\n",
    ")  # Encode male as 1, female as 0\n",
    "\n",
    "# Division des données en ensembles d'entraînement et de validation\n",
    "train_texts, val_texts, train_targets, val_targets = train_test_split(texts, targets, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialisation du tokenizer et du modèle BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)  # 2 labels: male, female\n",
    "\n",
    "# Tokenisation des données\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
    "\n",
    "# Création des datasets PyTorch\n",
    "train_dataset = TensorDataset(\n",
    "    torch.tensor(train_encodings['input_ids']),\n",
    "    torch.tensor(train_encodings['attention_mask']),\n",
    "    torch.tensor(train_targets)\n",
    ")\n",
    "val_dataset = TensorDataset(\n",
    "    torch.tensor(val_encodings['input_ids']),\n",
    "    torch.tensor(val_encodings['attention_mask']),\n",
    "    torch.tensor(val_targets)\n",
    ")\n",
    "\n",
    "# Paramètres d'entraînement\n",
    "batch_size = 16\n",
    "num_epochs = 3\n",
    "learning_rate = 2e-5\n",
    "\n",
    "# Création des dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# Configuration de l'optimiseur\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Entraînement du modèle\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        input_ids, attention_mask, labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}: Average training loss = {avg_train_loss:.4f}\")\n",
    "\n",
    "# Évaluation du modèle sur l'ensemble de validation\n",
    "model.eval()\n",
    "val_preds = []\n",
    "val_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        input_ids, attention_mask, labels = tuple(t.to(device) for t in batch)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        val_preds.extend(preds)\n",
    "        val_true.extend(labels.cpu().numpy())\n",
    "\n",
    "val_accuracy = accuracy_score(val_true, val_preds)\n",
    "print(f\"Validation accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jointure_data = pd.merge(\n",
    "    preprocessed_data,\n",
    "    name_data,\n",
    "    left_on=[\"firstname\"],\n",
    "    right_on=[\"firstname\"],\n",
    "    how=\"left\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
